#!/usr/bin/env python3
"""
Configuration Migration Engine â€” ç‰ˆæœ¬åŒ–é…ç½®é·ç§»ã€‚

éˆæ„Ÿä¾†æºï¼šGemini CLI çš„ storageMigration.ts
ç‚ºæ¯å€‹ YAML é…ç½®æª”æä¾›ç‰ˆæœ¬åŒ–é·ç§»è·¯å¾‘ï¼Œç¢ºä¿é…ç½®æ ¼å¼å‡ç´šçš„å¯é æ€§ã€‚

Usage:
  python hooks/config_migration.py --check    # ä¹¾è·‘ï¼Œé¡¯ç¤ºå¾…é·ç§»é …ç›®
  python hooks/config_migration.py --apply    # åŸ·è¡Œé·ç§»
  python hooks/config_migration.py --json     # JSON è¼¸å‡º
"""
import json
import os
import sys
import shutil
from datetime import datetime


def _load_yaml(filepath):
    """è¼‰å…¥ YAML æª”æ¡ˆã€‚"""
    try:
        import yaml
    except ImportError:
        return None

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except Exception:
        return None


def _save_yaml(filepath, data):
    """å„²å­˜ YAML æª”æ¡ˆã€‚"""
    try:
        import yaml
    except ImportError:
        return False

    try:
        with open(filepath, "w", encoding="utf-8") as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True,
                      sort_keys=False)
        return True
    except Exception:
        return False


def _backup_file(filepath):
    """å»ºç«‹å‚™ä»½æª”æ¡ˆã€‚"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{filepath}.backup.{timestamp}"
    shutil.copy2(filepath, backup_path)
    return backup_path


# ============================================
# Migration Functions
# ============================================

def migrate_hook_rules_v1_to_v2(data):
    """hook-rules.yaml v1 â†’ v2: åŠ å…¥ presets + priority æ¬„ä½ã€‚"""
    # åŠ å…¥ presets
    if "presets" not in data:
        data["presets"] = {
            "strict": {
                "description": "æ’ç¨‹åŸ·è¡Œï¼ˆé è¨­ï¼‰â€” å…¨éƒ¨è¦å‰‡å•Ÿç”¨",
                "disabled_rules": [],
            },
            "standard": {
                "description": "äº’å‹•é–‹ç™¼ â€” æ”¾å¯¬éé—œéµè¦å‰‡",
                "disabled_rules": ["sensitive-env"],
            },
            "permissive": {
                "description": "é™¤éŒ¯æ¨¡å¼ â€” åƒ…ä¿ç•™ critical è¦å‰‡",
                "disabled_rules": ["sensitive-env", "force-push"],
            },
        }

    # ç‚º bash_rules åŠ å…¥ priority
    priority_map = {
        "nul-redirect": "critical",
        "scheduler-state-write": "critical",
        "destructive-delete": "critical",
        "exfiltration": "critical",
        "force-push": "high",
        "sensitive-env": "medium",
    }
    for section in ["bash_rules", "write_rules", "read_rules"]:
        rules = data.get(section, [])
        if isinstance(rules, list):
            for rule in rules:
                if isinstance(rule, dict) and "priority" not in rule:
                    rule_id = rule.get("id", "")
                    rule["priority"] = priority_map.get(rule_id, "high")

    data["version"] = 2
    return data


def migrate_timeouts_v1_to_v2(data):
    """timeouts.yaml v1 â†’ v2: åŠ å…¥ loop_detection å€æ®µã€‚"""
    if "loop_detection" not in data:
        data["loop_detection"] = {
            "tool_hash_threshold": 5,
            "tool_hash_window": 20,
            "content_threshold": 3,
            "content_window": 10,
            "max_turns": {
                "digest": 80,
                "todoist": 150,
                "research": 100,
                "audit": 120,
                "default": 120,
            },
        }

    data["version"] = 2
    return data


def migrate_cache_policy_v1_to_v2(data):
    """cache-policy.yaml v1 â†’ v2: åŠ å…¥ circuit_breaker å€æ®µã€‚"""
    if "circuit_breaker" not in data:
        data["circuit_breaker"] = {
            "failure_threshold": 3,
            "cooldown_minutes": 30,
            "half_open_max_tries": 1,
        }

    data["version"] = 2
    return data


# ============================================
# Migration Registry
# ============================================

MIGRATIONS = {
    "hook-rules.yaml": {
        2: migrate_hook_rules_v1_to_v2,
    },
    "timeouts.yaml": {
        2: migrate_timeouts_v1_to_v2,
    },
    "cache-policy.yaml": {
        2: migrate_cache_policy_v1_to_v2,
    },
}


def get_config_dir():
    """å–å¾— config/ ç›®éŒ„è·¯å¾‘ã€‚"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(os.path.dirname(script_dir), "config")


def check_migrations(config_dir=None):
    """æª¢æŸ¥æ‰€æœ‰å¾…é€²è¡Œçš„é·ç§»ã€‚

    Returns:
        list of dict: [{filename, current_version, target_version, migration_count}]
    """
    if config_dir is None:
        config_dir = get_config_dir()

    pending = []
    for filename, version_migrations in MIGRATIONS.items():
        filepath = os.path.join(config_dir, filename)
        if not os.path.exists(filepath):
            continue

        data = _load_yaml(filepath)
        if data is None:
            continue

        current_version = data.get("version", 1)
        target_versions = sorted(v for v in version_migrations.keys()
                                 if v > current_version)

        if target_versions:
            pending.append({
                "filename": filename,
                "current_version": current_version,
                "target_version": target_versions[-1],
                "migration_count": len(target_versions),
            })

    return pending


def apply_migrations(config_dir=None, dry_run=False):
    """åŸ·è¡Œæ‰€æœ‰å¾…é€²è¡Œçš„é·ç§»ã€‚

    Returns:
        list of dict: [{filename, from_version, to_version, status, backup_path}]
    """
    if config_dir is None:
        config_dir = get_config_dir()

    results = []
    for filename, version_migrations in MIGRATIONS.items():
        filepath = os.path.join(config_dir, filename)
        if not os.path.exists(filepath):
            continue

        data = _load_yaml(filepath)
        if data is None:
            results.append({
                "filename": filename,
                "status": "error",
                "error": "YAML parse failed",
            })
            continue

        current_version = data.get("version", 1)
        target_versions = sorted(v for v in version_migrations.keys()
                                 if v > current_version)

        if not target_versions:
            continue

        from_version = current_version
        backup_path = None

        for target_version in target_versions:
            migrate_fn = version_migrations[target_version]

            if dry_run:
                results.append({
                    "filename": filename,
                    "from_version": from_version,
                    "to_version": target_version,
                    "status": "pending",
                })
                continue

            # å»ºç«‹å‚™ä»½ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡é·ç§»æ™‚ï¼‰
            if backup_path is None:
                backup_path = _backup_file(filepath)

            try:
                data = migrate_fn(data)
            except Exception as e:
                results.append({
                    "filename": filename,
                    "from_version": from_version,
                    "to_version": target_version,
                    "status": "error",
                    "error": str(e),
                    "backup_path": backup_path,
                })
                break

        if not dry_run and target_versions:
            if _save_yaml(filepath, data):
                results.append({
                    "filename": filename,
                    "from_version": from_version,
                    "to_version": target_versions[-1],
                    "status": "migrated",
                    "backup_path": backup_path,
                })
            else:
                results.append({
                    "filename": filename,
                    "from_version": from_version,
                    "to_version": target_versions[-1],
                    "status": "error",
                    "error": "YAML save failed",
                    "backup_path": backup_path,
                })

    return results


def main():
    if hasattr(sys.stdout, "reconfigure"):
        sys.stdout.reconfigure(encoding="utf-8")

    dry_run = "--check" in sys.argv
    do_apply = "--apply" in sys.argv
    json_output = "--json" in sys.argv

    if not dry_run and not do_apply:
        print("Usage:")
        print("  python hooks/config_migration.py --check    # æª¢æŸ¥å¾…é·ç§»é …ç›®")
        print("  python hooks/config_migration.py --apply    # åŸ·è¡Œé·ç§»")
        print("  python hooks/config_migration.py --json     # JSON è¼¸å‡º")
        sys.exit(0)

    if dry_run:
        pending = check_migrations()
        if json_output:
            print(json.dumps(pending, indent=2, ensure_ascii=False))
        elif not pending:
            print("âœ… æ‰€æœ‰é…ç½®æª”ç‰ˆæœ¬å·²æ˜¯æœ€æ–°")
        else:
            print(f"ğŸ“‹ å¾…é·ç§»é…ç½®æª”: {len(pending)} å€‹")
            for item in pending:
                print(f"  - {item['filename']}: v{item['current_version']} â†’ v{item['target_version']} ({item['migration_count']} æ­¥)")
        sys.exit(0)

    if do_apply:
        results = apply_migrations(dry_run=False)
        if json_output:
            print(json.dumps(results, indent=2, ensure_ascii=False))
        else:
            for r in results:
                status = r["status"]
                if status == "migrated":
                    print(f"  âœ… {r['filename']}: v{r['from_version']} â†’ v{r['to_version']} (å‚™ä»½: {r.get('backup_path', 'N/A')})")
                elif status == "error":
                    print(f"  âŒ {r['filename']}: {r.get('error', 'unknown error')}")
            if not results:
                print("âœ… ç„¡å¾…é·ç§»é …ç›®")


if __name__ == "__main__":
    main()
